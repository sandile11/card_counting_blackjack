{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception reporting mode: Plain\n"
     ]
    }
   ],
   "source": [
    "%xmode plain\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "suits_dict = {0:'Spade',1:'Heart', 2:'Club', 3:'Diamond'}\n",
    "ranks_dict = {0:'A', 1:'2', 2:'3', 3:'4', 4:'5', 5:'6', 6:'7', 7:'8', 8:'9', 9:'10', 10:'J', 11:'K', 12:'Q'}\n",
    "BKG_THRESH = 60\n",
    "CARD_THRESH = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattener(image, pts, w, h):\n",
    "    \"\"\"Flattens an image of a card into a top-down 200x300 perspective.\n",
    "    Returns the flattened, re-sized, grayed image.\n",
    "    See www.pyimagesearch.com/2014/08/25/4-point-opencv-getperspective-transform-example/\"\"\"\n",
    "    temp_rect = np.zeros((4,2), dtype = \"float32\")\n",
    "    \n",
    "    s = np.sum(pts, axis = 2)\n",
    "\n",
    "    tl = pts[np.argmin(s)]\n",
    "    br = pts[np.argmax(s)]\n",
    "    \n",
    "    diff = np.diff(pts, axis = -1)\n",
    "    tr = pts[np.argmin(diff)]\n",
    "    bl = pts[np.argmax(diff)]\n",
    "    \n",
    "#     pri\n",
    "    # Need to create an array listing points in order of\n",
    "    # [top left, top right, bottom right, bottom left]\n",
    "    # before doing the perspective transform\n",
    "\n",
    "    if w <= 0.8*h: # If card is vertically oriented\n",
    "        temp_rect[0] = tl\n",
    "        temp_rect[1] = tr\n",
    "        temp_rect[2] = br\n",
    "        temp_rect[3] = bl\n",
    "\n",
    "    if w >= 1.2*h: # If card is horizontally oriented\n",
    "        temp_rect[0] = bl\n",
    "        temp_rect[1] = tl\n",
    "        temp_rect[2] = tr\n",
    "        temp_rect[3] = br\n",
    "\n",
    "\n",
    "    if w > 0.8*h and w < 1.2*h: #If card is diamond oriented\n",
    "\n",
    "        if pts[1][0][1] <= pts[3][0][1]:\n",
    "            # If card is titled to the left, approxPolyDP returns points\n",
    "            # in this order: top right, top left, bottom left, bottom right\n",
    "            temp_rect[0] = pts[1][0] # Top left\n",
    "            temp_rect[1] = pts[0][0] # Top right\n",
    "            temp_rect[2] = pts[3][0] # Bottom right\n",
    "            temp_rect[3] = pts[2][0] # Bottom left\n",
    "\n",
    "        # If furthest left point is lower than furthest right point,\n",
    "        # card is tilted to the right\n",
    "        if pts[1][0][1] > pts[3][0][1]:\n",
    "            # If card is titled to the right, approxPolyDP returns points\n",
    "            # in this order: top left, bottom left, bottom right, top right\n",
    "            temp_rect[0] = pts[0][0] # Top left\n",
    "            temp_rect[1] = pts[3][0] # Top right\n",
    "            temp_rect[2] = pts[2][0] # Bottom right\n",
    "            temp_rect[3] = pts[1][0] # Bottom left\n",
    "            \n",
    "        \n",
    "    maxWidth = 200\n",
    "    maxHeight = 300\n",
    "\n",
    "    # Create destination array, calculate perspective transform matrix,\n",
    "    # and warp card image\n",
    "    dst = np.array([[0,0],[maxWidth-1,0],[maxWidth-1,maxHeight-1],[0, maxHeight-1]], np.float32)\n",
    "    M = cv2.getPerspectiveTransform(temp_rect,dst)\n",
    "    warp = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "\n",
    "    return warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_card(contour, img):\n",
    "    \n",
    "    peri = cv2.arcLength(contour, True)\n",
    "    approx = cv2.approxPolyDP(contour, 0.01*peri, True)\n",
    "    pts = np.float32(approx)\n",
    "    x,y,w,h = cv2.boundingRect(approx)\n",
    "    \n",
    "    warp = flattener(img, pts, w, h)\n",
    "    \n",
    "    ## Card image\n",
    "    warp = cv2.cvtColor(warp,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    CORNER_WIDTH = 30\n",
    "    CORNER_HEIGHT = 84\n",
    "    \n",
    "    cropped_suit = warp[0:CORNER_HEIGHT, 0:CORNER_WIDTH]\n",
    "    csuit = cv2.resize(cropped_suit, (0,0), fx=4, fy=4)\n",
    "    \n",
    "    white_level = csuit[15,int((CORNER_WIDTH*4)/2)]\n",
    "    thresh_level = white_level - 30 # CARD_THRESH\n",
    "    if (thresh_level <= 0):\n",
    "        thresh_level = 1\n",
    "        \n",
    "    retval, csuit = cv2.threshold(csuit, thresh_level, 255, cv2. THRESH_BINARY_INV)\n",
    "    \n",
    "    \n",
    "    half = int(csuit.shape[0]/2)\n",
    "        \n",
    "    return csuit[0:half,:] , csuit[half+1:half*2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=6000, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=50, bias=True)\n",
       "  (fc3): Linear(in_features=50, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_inputs=6000, num_classes=4):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_inputs, 50)\n",
    "        self.fc2 = nn.Linear(50, 50)\n",
    "        self.fc3 = nn.Linear(50, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = f.relu(self.fc1(x))\n",
    "        x = f.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "predict_suits = Net()\n",
    "predict_suits.load_state_dict(torch.load('./suits-model-1538689727.9620585.csv'))\n",
    "predict_suits.eval()\n",
    "predict_ranks = Net(num_classes=13)\n",
    "predict_ranks.load_state_dict(torch.load('./ranks-model-1538687613.6711135.csv'))\n",
    "predict_ranks.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the cards in the image and classify them\n",
    "mask = cv2.imread('./CV-BlackjackStudent/GOPR0318.MP4-lbl/00445-lbl.png',1)\n",
    "input_img = cv2.imread('./CV-BlackjackStudent/GOPR0318.MP4-lbl/00445.png',1)\n",
    "mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(mask,128,255,0)\n",
    "_, input_img_t = cv2.threshold(input_img,128,255,0)\n",
    "im2, num_cards, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "for i in range(len(num_cards)):\n",
    "    \n",
    "    card_value, card_suit = preprocess_card(num_cards[i], input_img)\n",
    "\n",
    "    im2, contours, hierarchy = cv2.findContours(card_value,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key=cv2.contourArea,reverse=True)\n",
    "    \n",
    "    x, y, w, h = cv2.boundingRect(contours[0])\n",
    "    isolated_rank = card_value[y:y+h, x:x+w]\n",
    "    im2, contours, hierarchy = cv2.findContours(card_suit,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key=cv2.contourArea,reverse=True)\n",
    "    \n",
    "    x, y, w, h = cv2.boundingRect(contours[0])\n",
    "    isolated_suit = card_suit[y:y+h, x:x+w]\n",
    "\n",
    "    ## Read in the card values\n",
    "    isolated_suit = cv2.resize(isolated_suit, (60, 100))\n",
    "    isolated_rank = cv2.resize(isolated_rank, (60, 100))\n",
    "\n",
    "    isolated_suit = isolated_suit.flatten()\n",
    "    isolated_rank = isolated_rank.flatten()\n",
    "    a = predict_suits(torch.tensor(isolated_suit, dtype=torch.float32)).max(0)[1].item()\n",
    "    b = predict_ranks(torch.tensor(isolated_rank, dtype=torch.float32)).max(0)[1].item() #find_rank(isolated_rank, ranks)\n",
    " \n",
    "    ## Put text on screen\n",
    "    text = \"Card: \" +  ranks_dict[b]+ ' of ' + suits_dict[a] +\"s\" \n",
    "    cv2.putText(input_img,  text, (50, (i+1)*100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), thickness=2,lineType=cv2.LINE_AA) \n",
    "  \n",
    "cv2.imshow('Scene',input_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
